{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-b6f6afadfb43>:85: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Student\\.conda\\envs\\Deep Learning\\lib\\site-packages\\tensorflow_core\\python\\layers\\core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-1-b6f6afadfb43>:86: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "WARNING:tensorflow:From <ipython-input-1-b6f6afadfb43>:95: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2DTranspose` instead.\n",
      "Tensor(\"Generator/conv2d_transpose_1/BiasAdd:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-1-b6f6afadfb43>:113: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "Epoch 0: Generator Loss: 0.761162, Discriminator Loss: 1.377263\n",
      "Epoch 5: Generator Loss: 1.021555, Discriminator Loss: 1.274880\n",
      "Epoch 10: Generator Loss: 1.134096, Discriminator Loss: 0.895338\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.reset_default_graph()\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        d = pickle.load(fo, encoding='latin1')\n",
    "    return d\n",
    "    \n",
    "\n",
    "def onehot(labels):\n",
    "    ''' one-hot encoding'''\n",
    "    n_sample = len(labels)\n",
    "    n_class = max(labels) + 1\n",
    "    onehot_labels = np.zeros((n_sample, n_class))\n",
    "    onehot_labels[np.arange(n_sample), labels] = 1\n",
    "\n",
    "    return onehot_labels\n",
    "\n",
    "def convert_images(raw):\n",
    "    '''\n",
    "    Convert images from the CIFAR-10 format and\n",
    "    return a 4-dim array with shape: [image_number, height, width, channel]\n",
    "    where the pixels are floats between 0.0 and 1.0.\n",
    "    '''\n",
    "\n",
    "    # Convert the raw images from the data-files to floating-points.\n",
    "    raw_float = np.array(raw, dtype=float) / 255.0\n",
    "    # Rescale to [-1, 1], the input range of the discriminator\n",
    "    raw_float = raw_float * 2 - 1\n",
    "    # Reshape the array to 4-dimensions.\n",
    "    images = raw_float.reshape([-1, 3, 32, 32])\n",
    "\n",
    "    # Reorder the indices of the array.\n",
    "    images = images.transpose([0, 2, 3, 1])\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "data1 = unpickle('cifar-10-batches-py/data_batch_1')\n",
    "data2 = unpickle('cifar-10-batches-py/data_batch_2')\n",
    "data3 = unpickle('cifar-10-batches-py/data_batch_3')\n",
    "data4 = unpickle('cifar-10-batches-py/data_batch_4')\n",
    "data5 = unpickle('cifar-10-batches-py/data_batch_5')\n",
    "\n",
    "X_train = np.concatenate((data1['data'], data2['data'], data3['data'], data4['data'], data5['data']), axis=0) \n",
    "X_train = convert_images(X_train)\n",
    "\n",
    "test = unpickle('cifar-10-batches-py/test_batch')\n",
    "X_test = test['data'] \n",
    "X_test = convert_images(X_test)\n",
    "\n",
    "# Training Params\n",
    "training_epochs = 150\n",
    "batch_size = 128\n",
    "lr_generator = 0.002\n",
    "lr_discriminator = 0.002\n",
    "\n",
    "# Network Params\n",
    "image_dim = 3072 # 32*32 pixels * 3 channel\n",
    "noise_dim = 100 # Noise data points\n",
    "\n",
    "# Build Networks\n",
    "# Network Inputs\n",
    "noise_input = tf.placeholder(tf.float32, shape=[None, noise_dim])\n",
    "real_image_input = tf.placeholder(tf.float32, shape=[None, 32, 32, 3])\n",
    "# A boolean to indicate batch normalization if it is training or inference time\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "#LeakyReLU activation\n",
    "def leakyrelu(x, alpha=0.2):\n",
    "    return 0.5 * (1 + alpha) * x + 0.5 * (1 - alpha) * abs(x)\n",
    "\n",
    "# Generator Network\n",
    "# Input: Noise, Output: Image\n",
    "# Note that batch normalization has different behavior at training and inference time,\n",
    "# we then use a placeholder to indicates the layer if we are training or not.\n",
    "def generator(x, reuse=False):\n",
    "    with tf.variable_scope('Generator', reuse=reuse):\n",
    "        # TensorFlow Layers automatically create variables and calculate their\n",
    "        # shape, based on the input.\n",
    "        x = tf.layers.dense(x, units=8 * 8 * 128)\n",
    "        x = tf.layers.batch_normalization(x, training=is_training)\n",
    "        x = tf.nn.relu(x)\n",
    "        # Reshape to a 4-D array of images: (batch, height, width, channels)\n",
    "        # New shape: (batch, 8, 8, 128)\n",
    "        #print(x)\n",
    "       \n",
    "        x = tf.reshape(x, shape=[-1, 8, 8, 128])\n",
    "        \n",
    "        # Deconvolution, image shape: (batch, 16, 16, 64)\n",
    "        x = tf.layers.conv2d_transpose(x, 64, 5, strides=2, padding='same')\n",
    "        \n",
    "        x = tf.layers.batch_normalization(x, training=is_training)\n",
    "        x = tf.nn.relu(x)\n",
    "        # Deconvolution, image shape: (batch, 32, 32, 3)\n",
    "        x = tf.layers.conv2d_transpose(x, 3, 5, strides=2, padding='same')\n",
    "        print(x)\n",
    "        # Apply tanh for better stability - clip values to [-1, 1].\n",
    "        x = tf.nn.tanh(x)\n",
    "      \n",
    "        return x\n",
    "\n",
    "\n",
    "# Discriminator Network\n",
    "# Input: Image, Output: Prediction Real/Fake Image\n",
    "def discriminator(x, reuse=False):\n",
    "    with tf.variable_scope('Discriminator', reuse=reuse):\n",
    "        # Typical convolutional neural network to classify images.\n",
    "        x = tf.layers.conv2d(x, 64, 5, strides=2, padding='same')\n",
    "        x = tf.layers.batch_normalization(x, training=is_training)\n",
    "        x = leakyrelu(x)\n",
    "        x = tf.layers.conv2d(x, 128, 5, strides=2, padding='same')\n",
    "        x = tf.layers.batch_normalization(x, training=is_training)\n",
    "        x = leakyrelu(x)\n",
    "     \n",
    "        # Flatten\n",
    "        x = tf.reshape(x, shape=[-1, 8*8*128])\n",
    "        x = tf.layers.dense(x, 1024)\n",
    "        x = tf.layers.batch_normalization(x, training=is_training)\n",
    "        x = leakyrelu(x)\n",
    "        # Output 2 classes: Real and Fake images\n",
    "        x = tf.layers.dense(x, 2)\n",
    "    return x\n",
    "\n",
    "# Build Generator Network\n",
    "gen_sample = generator(noise_input)\n",
    "\n",
    "# Build 2 Discriminator Networks (one from noise input, one from generated samples)\n",
    "disc_real = discriminator(real_image_input)\n",
    "disc_fake = discriminator(gen_sample, reuse=True)\n",
    "\n",
    "# Build the stacked generator/discriminator\n",
    "stacked_gan = discriminator(gen_sample, reuse=True)\n",
    "\n",
    "# Build Loss (Labels for real images: 1, for fake images: 0)\n",
    "# Discriminator Loss for real and fake samples\n",
    "disc_loss_real = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    logits=disc_real, labels=tf.ones([batch_size], dtype=tf.int32)))\n",
    "disc_loss_fake = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    logits=disc_fake, labels=tf.zeros([batch_size], dtype=tf.int32)))\n",
    "# Sum both loss\n",
    "disc_loss = disc_loss_real + disc_loss_fake\n",
    "# Generator Loss (The generator tries to fool the discriminator, thus labels are 1)\n",
    "gen_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    logits=stacked_gan, labels=tf.ones([batch_size], dtype=tf.int32)))\n",
    "\n",
    "# Build Optimizers\n",
    "optimizer_gen = tf.train.AdamOptimizer(learning_rate=lr_generator, beta1=0.5, beta2=0.999)\n",
    "optimizer_disc = tf.train.AdamOptimizer(learning_rate=lr_discriminator, beta1=0.5, beta2=0.999)\n",
    "\n",
    "# Training Variables for each optimizer\n",
    "# By default in TensorFlow, all variables are updated by each optimizer, so we\n",
    "# need to precise for each one of them the specific variables to update.\n",
    "# Generator Network Variables\n",
    "gen_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='Generator')\n",
    "# Discriminator Network Variables\n",
    "disc_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='Discriminator')\n",
    "\n",
    "# Create training operations\n",
    "# TensorFlow UPDATE_OPS collection holds all batch norm operation to update the moving mean/stddev\n",
    "gen_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope='Generator')\n",
    "# `control_dependencies` ensure that the `gen_update_ops` will be run before the `minimize` op (backprop)\n",
    "with tf.control_dependencies(gen_update_ops):\n",
    "    train_gen = optimizer_gen.minimize(gen_loss, var_list=gen_vars)\n",
    "disc_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope='Discriminator')\n",
    "with tf.control_dependencies(disc_update_ops):\n",
    "    train_disc = optimizer_disc.minimize(disc_loss, var_list=disc_vars)\n",
    "\n",
    "    \n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(training_epochs):\n",
    "    \n",
    "        total_batch = int(X_train.shape[0] / batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_x = X_train[i*batch_size:(i+1)*batch_size]\n",
    "            #batch_x = convert_images(batch_x)\n",
    "\n",
    "            # Discriminator Training\n",
    "            # Generate noise to feed to the generator\n",
    "            z = np.random.uniform(-1., 1., size=[batch_size, noise_dim])\n",
    "            _, dl = sess.run([train_disc, disc_loss], feed_dict={real_image_input: batch_x, noise_input: z, is_training:True})\n",
    "    \n",
    "            # Generator Training\n",
    "            # Generate noise to feed to the generator\n",
    "            z = np.random.uniform(-1., 1., size=[batch_size, noise_dim])\n",
    "            _, gl = sess.run([train_gen, gen_loss], feed_dict={noise_input: z, is_training:True})\n",
    "    \n",
    "        if epoch % 5 == 0:\n",
    "            print('Epoch %i: Generator Loss: %f, Discriminator Loss: %f' % (epoch, gl, dl))\n",
    "    # Testing\n",
    "    # Generate images from noise, using the generator network.\n",
    "    n = 10\n",
    "    canvas = np.empty((32 * n, 32 * n, 3))\n",
    "    for i in range(n):\n",
    "        # Noise input.\n",
    "        z = np.random.uniform(-1., 1., size=[n, noise_dim])\n",
    "        # Generate image from noise.\n",
    "        g = sess.run(gen_sample, feed_dict={noise_input: z, is_training:False})\n",
    "        # Rescale values to the original [0, 1] (from tanh -> [-1, 1])\n",
    "        g = (g + 1.) / 2.\n",
    "        # Reverse colours for better display\n",
    "        g = (g*255).astype(np.uint8)   # 乘回原圖尺寸\n",
    "        #images = raw_float.reshape([-1, 3, 32, 32])\n",
    "\n",
    "                \n",
    "        f, a = plt.subplots(1, n, figsize=(n, 1))\n",
    "        for i in range(n):\n",
    "            a[i].imshow(g[i])\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
